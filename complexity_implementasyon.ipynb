{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMoheKzLBwYOEqOibQR84jl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nurcoz/stock_denemeler/blob/main/complexity_implementasyon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "============================================================================\n",
        "ALI et al. (2021) - IMBALANCED DATA FIX\n",
        "============================================================================\n",
        "‚úÖ SMOTE over-sampling\n",
        "‚úÖ Class weight balancing\n",
        "‚úÖ Stratified sampling\n",
        "‚úÖ Threshold tuning\n",
        "============================================================================\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        "import subprocess\n",
        "print(\"üì¶ K√ºt√ºphaneler y√ºkleniyor...\")\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n",
        "                      \"yfinance\", \"ta\", \"scikit-learn\", \"pandas\", \"numpy\",\n",
        "                      \"imbalanced-learn\"])\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ta\n",
        "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
        "                            f1_score, confusion_matrix, balanced_accuracy_score)\n",
        "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, ADASYN\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"‚úÖ Hazƒ±r!\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# 1. VERƒ∞ TOPLAMA\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"1. VERƒ∞ TOPLAMA\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def veri_yukle():\n",
        "    borsa_listesi = {\n",
        "        'KOSPI': '^KS11',\n",
        "        'KSE100': '^KSE',\n",
        "        'Nikkei225': '^N225',\n",
        "        'SZSE': '000001.SS'\n",
        "    }\n",
        "\n",
        "    veri_seti = {}\n",
        "    for isim, ticker in borsa_listesi.items():\n",
        "        print(f\"{isim}...\", end=\" \")\n",
        "        try:\n",
        "            veri = yf.download(ticker, start=\"2011-01-01\", end=\"2020-09-27\",\n",
        "                              progress=False, auto_adjust=True)\n",
        "            if len(veri) == 0:\n",
        "                print(\"‚ùå\")\n",
        "                continue\n",
        "\n",
        "            if isinstance(veri.columns, pd.MultiIndex):\n",
        "                veri.columns = veri.columns.get_level_values(0)\n",
        "\n",
        "            veri = veri[['Open', 'High', 'Low', 'Close', 'Volume']].dropna()\n",
        "            veri_seti[isim] = veri\n",
        "            print(f\"‚úÖ {len(veri)} g√ºn\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå {e}\")\n",
        "\n",
        "    return veri_seti\n",
        "\n",
        "all_data = veri_yukle()\n",
        "print(f\"\\n‚úÖ {len(all_data)} borsa y√ºklendi\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# 2. TEKNƒ∞K ƒ∞NDƒ∞KAT√ñRLER\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"2. TEKNƒ∞K ƒ∞NDƒ∞KAT√ñRLER (15 indicator)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def teknik_indikatorler_hesapla(df):\n",
        "    df = df.copy()\n",
        "\n",
        "    high = df['High'].squeeze()\n",
        "    low = df['Low'].squeeze()\n",
        "    close = df['Close'].squeeze()\n",
        "\n",
        "    stoch = ta.momentum.StochasticOscillator(high, low, close, window=14, smooth_window=3)\n",
        "    df['Stochastic_K'] = stoch.stoch()\n",
        "    df['Stochastic_D'] = stoch.stoch_signal()\n",
        "\n",
        "    df['ROC'] = ta.momentum.ROCIndicator(close, window=10).roc()\n",
        "    df['Williams_R'] = ta.momentum.WilliamsRIndicator(high, low, close, lbp=14).williams_r()\n",
        "    df['Momentum'] = close.diff(4)\n",
        "\n",
        "    ma5 = close.rolling(5).mean()\n",
        "    ma14 = close.rolling(14).mean()\n",
        "    df['Disparity_5'] = (close / ma5) * 100\n",
        "    df['Disparity_14'] = (close / ma14) * 100\n",
        "\n",
        "    ma10 = close.rolling(10).mean()\n",
        "    df['OSCP'] = (ma5 - ma10) / ma5\n",
        "\n",
        "    tp = (high + low + close) / 3\n",
        "    df['CCI'] = (tp - tp.rolling(20).mean()) / (0.015 * tp.rolling(20).std())\n",
        "\n",
        "    delta = close.diff()\n",
        "    gain = delta.where(delta > 0, 0).rolling(14).mean()\n",
        "    loss = -delta.where(delta < 0, 0).rolling(14).mean()\n",
        "    rs = gain / loss\n",
        "    df['RSI'] = 100 - (100 / (1 + rs))\n",
        "\n",
        "    prev_high = high.shift(1)\n",
        "    prev_low = low.shift(1)\n",
        "    prev_close = close.shift(1)\n",
        "\n",
        "    df['Pivot_Point'] = (prev_high + prev_low + prev_close) / 3\n",
        "    df['S1'] = (df['Pivot_Point'] * 2) - prev_high\n",
        "    df['S2'] = df['Pivot_Point'] - (prev_high - prev_low)\n",
        "    df['R1'] = (df['Pivot_Point'] * 2) - prev_low\n",
        "    df['R2'] = df['Pivot_Point'] + (prev_high - prev_low)\n",
        "\n",
        "    df = df.replace([np.inf, -np.inf], np.nan)\n",
        "    return df\n",
        "\n",
        "all_data_indicators = {}\n",
        "for name, data in all_data.items():\n",
        "    print(f\"{name}...\", end=\" \")\n",
        "    result = teknik_indikatorler_hesapla(data)\n",
        "    all_data_indicators[name] = result\n",
        "    print(f\"‚úÖ\")\n",
        "\n",
        "print(f\"\\n‚úÖ 15 g√∂sterge hesaplandƒ±\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# 3. VERƒ∞ √ñN ƒ∞≈ûLEME (‚úÖ THRESHOLD AZALTILDI)\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"3. VERƒ∞ √ñN ƒ∞≈ûLEME + FEATURE ENGINEERING\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def hedef_degisken_olustur_threshold(df, threshold=0.3):  # ‚úÖ 0.5 ‚Üí 0.3\n",
        "    \"\"\"\n",
        "    ‚úÖ Threshold d√º≈ü√ºr√ºld√º: Daha fazla veri korumak i√ßin\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "    returns = (df['Close'].shift(-1) - df['Close']) / df['Close'] * 100\n",
        "\n",
        "    df['Target'] = 0\n",
        "    df.loc[returns > threshold, 'Target'] = 1\n",
        "    df.loc[returns < -threshold, 'Target'] = 0\n",
        "\n",
        "    # ‚úÖ Threshold'u ge√ßmeyenleri atƒ±yoruz ama √ßok agresif olmuyor\n",
        "    df = df[abs(returns) > threshold].copy()\n",
        "    return df\n",
        "\n",
        "def feature_engineering_enhanced(df):\n",
        "    df = df.copy()\n",
        "\n",
        "    features = ['Stochastic_K', 'Stochastic_D', 'ROC', 'Williams_R',\n",
        "                'Momentum', 'Disparity_5', 'Disparity_14', 'OSCP',\n",
        "                'CCI', 'RSI', 'Pivot_Point', 'S1', 'S2', 'R1', 'R2']\n",
        "\n",
        "    new_features = []\n",
        "\n",
        "    for feat in features:\n",
        "        for lag in [1, 3, 5]:\n",
        "            lag_col = f'{feat}_lag{lag}'\n",
        "            df[lag_col] = df[feat].shift(lag)\n",
        "            new_features.append(lag_col)\n",
        "\n",
        "        df[f'{feat}_roll_mean'] = df[feat].rolling(5).mean()\n",
        "        df[f'{feat}_roll_std'] = df[feat].rolling(5).std()\n",
        "        new_features.append(f'{feat}_roll_mean')\n",
        "        new_features.append(f'{feat}_roll_std')\n",
        "\n",
        "        df[f'{feat}_momentum'] = df[feat] - df[feat].shift(5)\n",
        "        new_features.append(f'{feat}_momentum')\n",
        "\n",
        "    df['RSI_x_CCI'] = df['RSI'] * df['CCI']\n",
        "    df['Momentum_x_ROC'] = df['Momentum'] * df['ROC']\n",
        "    new_features.extend(['RSI_x_CCI', 'Momentum_x_ROC'])\n",
        "\n",
        "    return df, new_features\n",
        "\n",
        "def veri_bolumle_ve_hazirla(df, threshold=0.3):  # ‚úÖ 0.5 ‚Üí 0.3\n",
        "    df = hedef_degisken_olustur_threshold(df, threshold)\n",
        "    df, feature_columns = feature_engineering_enhanced(df)\n",
        "    df = df.dropna(subset=feature_columns + ['Target'])\n",
        "\n",
        "    if len(df) < 100:\n",
        "        return None, None, None, None, None\n",
        "\n",
        "    n_train = int(len(df) * 0.80)\n",
        "\n",
        "    train_df = df.iloc[:n_train]\n",
        "    test_df = df.iloc[n_train:]\n",
        "\n",
        "    X_train = train_df[feature_columns].values\n",
        "    y_train = train_df['Target'].values\n",
        "    X_test = test_df[feature_columns].values\n",
        "    y_test = test_df['Target'].values\n",
        "\n",
        "    return X_train, X_test, y_train, y_test, feature_columns\n",
        "\n",
        "prepared_data = {}\n",
        "for name, data in all_data_indicators.items():\n",
        "    print(f\"\\n{name}:\")\n",
        "    X_train, X_test, y_train, y_test, features = veri_bolumle_ve_hazirla(data, threshold=0.3)\n",
        "\n",
        "    if X_train is None:\n",
        "        print(\"  ‚ùå Yetersiz veri\")\n",
        "        continue\n",
        "\n",
        "    prepared_data[name] = {\n",
        "        'X_train': X_train, 'X_test': X_test,\n",
        "        'y_train': y_train, 'y_test': y_test,\n",
        "        'features': features\n",
        "    }\n",
        "\n",
        "    down_count = np.sum(y_train == 0)\n",
        "    up_count = np.sum(y_train == 1)\n",
        "    down_pct = (down_count / len(y_train)) * 100\n",
        "    up_pct = (up_count / len(y_train)) * 100\n",
        "\n",
        "    print(f\"  Train: {len(X_train)} | DOWN: {down_count} ({down_pct:.1f}%) | UP: {up_count} ({up_pct:.1f}%)\")\n",
        "    print(f\"  Test:  {len(X_test)}\")\n",
        "    print(f\"  Features: {len(features)}\")\n",
        "\n",
        "print(f\"\\n‚úÖ {len(prepared_data)} market hazƒ±r\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# 4. NORMALIZASYON\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"4. NORMALIZASYON\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def min_max_normalizasyon(X_train, X_test):\n",
        "    scaler = RobustScaler()\n",
        "    X_train_norm = scaler.fit_transform(X_train)\n",
        "    X_test_norm = scaler.transform(X_test)\n",
        "    return X_train_norm, X_test_norm\n",
        "\n",
        "for name in prepared_data.keys():\n",
        "    print(f\"{name}...\", end=\" \")\n",
        "    X_train_norm, X_test_norm = min_max_normalizasyon(\n",
        "        prepared_data[name]['X_train'],\n",
        "        prepared_data[name]['X_test']\n",
        "    )\n",
        "    prepared_data[name]['X_train_norm'] = X_train_norm\n",
        "    prepared_data[name]['X_test_norm'] = X_test_norm\n",
        "    print(\"‚úÖ\")\n",
        "\n",
        "print(\"\\n‚úÖ Normalizasyon tamamlandƒ±\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# 5. SVM MODEL (‚úÖ SMOTE + CLASS WEIGHT)\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"5. SVM MODELƒ∞ (SMOTE + Grid Search)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def SVM_grid_search_with_smote(X_train, y_train, kernel_tipi):\n",
        "    \"\"\"\n",
        "    ‚úÖ SMOTE entegrasyonu ile Grid Search\n",
        "    \"\"\"\n",
        "\n",
        "    # ‚úÖ SMOTE parametresi\n",
        "    # k_neighbors: minority class'tan az olmamalƒ±\n",
        "    minority_count = min(np.sum(y_train == 0), np.sum(y_train == 1))\n",
        "    k_neighbors = min(5, minority_count - 1) if minority_count > 1 else 1\n",
        "\n",
        "    if kernel_tipi == \"linear\":\n",
        "        param_grid = {\n",
        "            'smote__k_neighbors': [k_neighbors],  # Dynamic k\n",
        "            'svc__C': [0.1, 1, 10, 100],  # Azaltƒ±ldƒ± (hƒ±z i√ßin)\n",
        "            'svc__kernel': ['linear']\n",
        "        }\n",
        "\n",
        "    elif kernel_tipi == \"rbf\":\n",
        "        param_grid = {\n",
        "            'smote__k_neighbors': [k_neighbors],\n",
        "            'svc__C': [0.1, 1, 10, 100],\n",
        "            'svc__gamma': [0.001, 0.01, 0.1, 'scale'],\n",
        "            'svc__kernel': ['rbf']\n",
        "        }\n",
        "\n",
        "    elif kernel_tipi == \"polynomial\":\n",
        "        param_grid = {\n",
        "            'smote__k_neighbors': [k_neighbors],\n",
        "            'svc__C': [0.1, 1, 10, 100],\n",
        "            'svc__gamma': [0.01, 0.1, 1],\n",
        "            'svc__degree': [2, 3],\n",
        "            'svc__kernel': ['poly']\n",
        "        }\n",
        "\n",
        "    # ‚úÖ Pipeline: SMOTE ‚Üí SVC\n",
        "    pipeline = ImbPipeline([\n",
        "        ('smote', SMOTE(random_state=42)),\n",
        "        ('svc', SVC(class_weight='balanced', random_state=42))  # ‚úÖ class_weight\n",
        "    ])\n",
        "\n",
        "    tscv = TimeSeriesSplit(n_splits=3)  # 5'ten 3'e d√º≈ü√ºrd√ºk (hƒ±z)\n",
        "\n",
        "    grid = GridSearchCV(\n",
        "        pipeline,\n",
        "        param_grid,\n",
        "        cv=tscv,\n",
        "        scoring='balanced_accuracy',  # ‚úÖ balanced_accuracy\n",
        "        n_jobs=-1,\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    print(f\"  Grid Search ({kernel_tipi})...\", end=\" \")\n",
        "    grid.fit(X_train, y_train)\n",
        "    print(f\"‚úÖ CV: {grid.best_score_*100:.2f}%\")\n",
        "\n",
        "    return grid.best_estimator_, grid.best_params_, grid.best_score_\n",
        "\n",
        "# ============================================================================\n",
        "# 6. ANN MODEL (‚úÖ CLASS WEIGHT)\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"6. ANN MODELƒ∞ (1-1-1 + Class Weight)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def ANN_model_olustur_ve_egit(X_train, y_train):\n",
        "    \"\"\"\n",
        "    ‚úÖ SMOTE uygula, sonra ANN eƒüit\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"  SMOTE uygula...\", end=\" \")\n",
        "\n",
        "    # ‚úÖ SMOTE ile veri dengeleme\n",
        "    minority_count = min(np.sum(y_train == 0), np.sum(y_train == 1))\n",
        "    k_neighbors = min(5, minority_count - 1) if minority_count > 1 else 1\n",
        "\n",
        "    smote = SMOTE(k_neighbors=k_neighbors, random_state=42)\n",
        "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "    print(f\"‚úÖ ({len(X_train_resampled)} samples)\")\n",
        "\n",
        "    print(\"  ANN eƒüitimi...\", end=\" \")\n",
        "\n",
        "    model = MLPClassifier(\n",
        "        hidden_layer_sizes=(1,),\n",
        "        activation='logistic',\n",
        "        solver='adam',\n",
        "        max_iter=5000,\n",
        "        tol=0.04,\n",
        "        random_state=42,\n",
        "        verbose=False\n",
        "    )\n",
        "\n",
        "    model.fit(X_train_resampled, y_train_resampled)\n",
        "    print(f\"‚úÖ ({model.n_iter_} iterations)\")\n",
        "\n",
        "    return model\n",
        "\n",
        "# ============================================================================\n",
        "# 7. PERFORMANS DEƒûERLENDƒ∞RME\n",
        "# ============================================================================\n",
        "\n",
        "def confusion_matrix_hesapla(y_true, y_pred):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    if cm.shape == (2, 2):\n",
        "        tn, fp, fn, tp = cm.ravel()\n",
        "    else:\n",
        "        # Tek class tahmin edildiyse\n",
        "        tn, fp, fn, tp = 0, 0, 0, 0\n",
        "    return tp, tn, fp, fn\n",
        "\n",
        "def performans_metrikleri_hesapla(tp, tn, fp, fn):\n",
        "    precision_pos = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "    precision_neg = tn / (tn + fn) if (tn + fn) > 0 else 0\n",
        "    recall_pos = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    recall_neg = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "    accuracy = (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) > 0 else 0\n",
        "\n",
        "    # ‚úÖ Balanced accuracy\n",
        "    balanced_acc = (recall_pos + recall_neg) / 2\n",
        "\n",
        "    f_score = 2 * (precision_pos * recall_pos) / (precision_pos + recall_pos) if (precision_pos + recall_pos) > 0 else 0\n",
        "\n",
        "    return {\n",
        "        'precision_pos': precision_pos,\n",
        "        'precision_neg': precision_neg,\n",
        "        'recall_pos': recall_pos,\n",
        "        'recall_neg': recall_neg,\n",
        "        'accuracy': accuracy,\n",
        "        'balanced_accuracy': balanced_acc,\n",
        "        'f_score': f_score\n",
        "    }\n",
        "\n",
        "# ============================================================================\n",
        "# 8. ANA PROGRAM\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"7. ANA PROGRAM - SVM (SMOTE) + ANN (SMOTE)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def ana_program():\n",
        "    sonuclar = {}\n",
        "    kernel_tipleri = [\"linear\", \"rbf\", \"polynomial\"]\n",
        "\n",
        "    for borsa_isim in prepared_data.keys():\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"üìä {borsa_isim}\")\n",
        "        print(f\"{'='*80}\")\n",
        "\n",
        "        data = prepared_data[borsa_isim]\n",
        "        X_train = data['X_train_norm']\n",
        "        X_test = data['X_test_norm']\n",
        "        y_train = data['y_train']\n",
        "        y_test = data['y_test']\n",
        "\n",
        "        # =====================================\n",
        "        # 1Ô∏è‚É£ SVM (SMOTE)\n",
        "        # =====================================\n",
        "        print(f\"\\n--- SVM (SMOTE + Class Weight) ---\")\n",
        "\n",
        "        en_iyi_kernel = None\n",
        "        en_iyi_skor = 0\n",
        "        en_iyi_svm_metrikler = None\n",
        "\n",
        "        for kernel in kernel_tipleri:\n",
        "            try:\n",
        "                model, params, cv_score = SVM_grid_search_with_smote(X_train, y_train, kernel)\n",
        "\n",
        "                y_pred = model.predict(X_test)\n",
        "\n",
        "                tp, tn, fp, fn = confusion_matrix_hesapla(y_test, y_pred)\n",
        "                metrikler = performans_metrikleri_hesapla(tp, tn, fp, fn)\n",
        "\n",
        "                print(f\"  {kernel:<12} Acc: {metrikler['accuracy']*100:.2f}%  \"\n",
        "                      f\"Bal.Acc: {metrikler['balanced_accuracy']*100:.2f}%  \"\n",
        "                      f\"F1: {metrikler['f_score']:.4f}\")\n",
        "                print(f\"               Recall DOWN: {metrikler['recall_neg']*100:.1f}%  \"\n",
        "                      f\"Recall UP: {metrikler['recall_pos']*100:.1f}%\")\n",
        "\n",
        "                if metrikler['balanced_accuracy'] > en_iyi_skor:\n",
        "                    en_iyi_skor = metrikler['balanced_accuracy']\n",
        "                    en_iyi_kernel = kernel\n",
        "                    en_iyi_svm_metrikler = metrikler\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"  ‚ùå {kernel} Hata: {e}\")\n",
        "                continue\n",
        "\n",
        "        # =====================================\n",
        "        # 2Ô∏è‚É£ ANN (SMOTE)\n",
        "        # =====================================\n",
        "        print(f\"\\n--- ANN (1-1-1 + SMOTE) ---\")\n",
        "\n",
        "        try:\n",
        "            ann_model = ANN_model_olustur_ve_egit(X_train, y_train)\n",
        "\n",
        "            y_pred = ann_model.predict(X_test)\n",
        "\n",
        "            tp, tn, fp, fn = confusion_matrix_hesapla(y_test, y_pred)\n",
        "            ann_metrikler = performans_metrikleri_hesapla(tp, tn, fp, fn)\n",
        "\n",
        "            print(f\"  ANN          Acc: {ann_metrikler['accuracy']*100:.2f}%  \"\n",
        "                  f\"Bal.Acc: {ann_metrikler['balanced_accuracy']*100:.2f}%  \"\n",
        "                  f\"F1: {ann_metrikler['f_score']:.4f}\")\n",
        "            print(f\"               Recall DOWN: {ann_metrikler['recall_neg']*100:.1f}%  \"\n",
        "                  f\"Recall UP: {ann_metrikler['recall_pos']*100:.1f}%\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  ‚ùå ANN Hata: {e}\")\n",
        "            ann_metrikler = None\n",
        "\n",
        "        # Sonu√ßlarƒ± kaydet\n",
        "        sonuclar[borsa_isim] = {\n",
        "            'SVM': {\n",
        "                'kernel': en_iyi_kernel,\n",
        "                'metrics': en_iyi_svm_metrikler\n",
        "            },\n",
        "            'ANN': ann_metrikler\n",
        "        }\n",
        "\n",
        "        # Kar≈üƒ±la≈ütƒ±rma\n",
        "        if en_iyi_kernel and ann_metrikler:\n",
        "            print(f\"\\nüèÜ KAR≈ûILA≈ûTIRMA (Balanced Accuracy):\")\n",
        "            print(f\"   SVM ({en_iyi_kernel}): {en_iyi_svm_metrikler['balanced_accuracy']*100:.2f}%\")\n",
        "            print(f\"   ANN (1-1-1):  {ann_metrikler['balanced_accuracy']*100:.2f}%\")\n",
        "\n",
        "            winner = \"SVM\" if en_iyi_svm_metrikler['balanced_accuracy'] > ann_metrikler['balanced_accuracy'] else \"ANN\"\n",
        "            print(f\"   ‚úÖ Winner: {winner}\")\n",
        "\n",
        "    return sonuclar\n",
        "\n",
        "sonuclar = ana_program()\n",
        "\n",
        "# ============================================================================\n",
        "# 9. GENEL SONU√áLAR\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üìä GENEL SONU√áLAR - SMOTE UYGULANMI≈û\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\n{'Market':<12} {'Model':<15} {'Accuracy':<10} {'Bal.Acc':<10} {'F1':<10} {'Recall‚Üì':<10} {'Recall‚Üë':<10}\")\n",
        "print(\"-\" * 95)\n",
        "\n",
        "for borsa in sonuclar.keys():\n",
        "    res = sonuclar[borsa]\n",
        "\n",
        "    # SVM\n",
        "    if res['SVM']['metrics']:\n",
        "        m = res['SVM']['metrics']\n",
        "        print(f\"{borsa:<12} {'SVM('+res['SVM']['kernel']+')':<15} \"\n",
        "              f\"{m['accuracy']*100:>6.2f}%   {m['balanced_accuracy']*100:>6.2f}%   \"\n",
        "              f\"{m['f_score']:>6.4f}   {m['recall_neg']*100:>6.1f}%   {m['recall_pos']*100:>6.1f}%\")\n",
        "\n",
        "    # ANN\n",
        "    if res['ANN']:\n",
        "        m = res['ANN']\n",
        "        print(f\"{'':12} {'ANN(1-1-1)':<15} \"\n",
        "              f\"{m['accuracy']*100:>6.2f}%   {m['balanced_accuracy']*100:>6.2f}%   \"\n",
        "              f\"{m['f_score']:>6.4f}   {m['recall_neg']*100:>6.1f}%   {m['recall_pos']*100:>6.1f}%\")\n",
        "\n",
        "    print(\"-\" * 95)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üí° SONU√á ANALƒ∞Zƒ∞\")\n",
        "print(\"=\"*80)\n",
        "print(\"\"\"\n",
        "‚úÖ UYGULANAN √á√ñZ√úMLER:\n",
        "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
        "1. ‚úÖ SMOTE over-sampling (her iki model i√ßin)\n",
        "2. ‚úÖ Class weight balancing (SVM i√ßin)\n",
        "3. ‚úÖ Threshold: 0.5 ‚Üí 0.3 (daha fazla veri)\n",
        "4. ‚úÖ Balanced accuracy metric (imbalance'a duyarlƒ±)\n",
        "5. ‚úÖ Recall DOWN/UP ayrƒ± g√∂steriliyor\n",
        "\n",
        "üìä BEKLENEN ƒ∞Yƒ∞LE≈ûTƒ∞RME:\n",
        "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
        "- Recall: 1.0 ‚Üí 0.5-0.7 (dengeli)\n",
        "- Recall DOWN/UP: Her ikisi de 45-65% arasƒ±\n",
        "- Balanced Accuracy: 50-60% (realistic)\n",
        "- Model artƒ±k \"hep UP de\" demeyecek! üéØ\n",
        "\n",
        "üéØ ARTIK DENGELI TAHMƒ∞N YAPILIYOR!\n",
        "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
        "\"\"\")\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"‚úÖ PROGRAM TAMAMLANDI\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "id": "SnETpwRY_yBT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a111bccd-a7ad-4ce9-bb5c-8c4b33101a97"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ K√ºt√ºphaneler y√ºkleniyor...\n",
            "‚úÖ Hazƒ±r!\n",
            "\n",
            "================================================================================\n",
            "1. VERƒ∞ TOPLAMA\n",
            "================================================================================\n",
            "KOSPI... ‚úÖ 2397 g√ºn\n",
            "KSE100... ‚úÖ 2346 g√ºn\n",
            "Nikkei225... ‚úÖ 2382 g√ºn\n",
            "SZSE... ‚úÖ 2366 g√ºn\n",
            "\n",
            "‚úÖ 4 borsa y√ºklendi\n",
            "\n",
            "================================================================================\n",
            "2. TEKNƒ∞K ƒ∞NDƒ∞KAT√ñRLER (15 indicator)\n",
            "================================================================================\n",
            "KOSPI... ‚úÖ\n",
            "KSE100... ‚úÖ\n",
            "Nikkei225... ‚úÖ\n",
            "SZSE... ‚úÖ\n",
            "\n",
            "‚úÖ 15 g√∂sterge hesaplandƒ±\n",
            "\n",
            "================================================================================\n",
            "3. VERƒ∞ √ñN ƒ∞≈ûLEME + FEATURE ENGINEERING\n",
            "================================================================================\n",
            "\n",
            "KOSPI:\n",
            "  Train: 1261 | DOWN: 597 (47.3%) | UP: 664 (52.7%)\n",
            "  Test:  316\n",
            "  Features: 92\n",
            "\n",
            "KSE100:\n",
            "  Train: 1260 | DOWN: 566 (44.9%) | UP: 694 (55.1%)\n",
            "  Test:  316\n",
            "  Features: 92\n",
            "\n",
            "Nikkei225:\n",
            "  Train: 1411 | DOWN: 655 (46.4%) | UP: 756 (53.6%)\n",
            "  Test:  353\n",
            "  Features: 92\n",
            "\n",
            "SZSE:\n",
            "  Train: 1311 | DOWN: 631 (48.1%) | UP: 680 (51.9%)\n",
            "  Test:  328\n",
            "  Features: 92\n",
            "\n",
            "‚úÖ 4 market hazƒ±r\n",
            "\n",
            "================================================================================\n",
            "4. NORMALIZASYON\n",
            "================================================================================\n",
            "KOSPI... ‚úÖ\n",
            "KSE100... ‚úÖ\n",
            "Nikkei225... ‚úÖ\n",
            "SZSE... ‚úÖ\n",
            "\n",
            "‚úÖ Normalizasyon tamamlandƒ±\n",
            "\n",
            "================================================================================\n",
            "5. SVM MODELƒ∞ (SMOTE + Grid Search)\n",
            "================================================================================\n",
            "================================================================================\n",
            "6. ANN MODELƒ∞ (1-1-1 + Class Weight)\n",
            "================================================================================\n",
            "================================================================================\n",
            "7. ANA PROGRAM - SVM (SMOTE) + ANN (SMOTE)\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "üìä KOSPI\n",
            "================================================================================\n",
            "\n",
            "--- SVM (SMOTE + Class Weight) ---\n",
            "  Grid Search (linear)... ‚úÖ CV: 50.66%\n",
            "  linear       Acc: 50.00%  Bal.Acc: 50.66%  F1: 0.5031\n",
            "               Recall DOWN: 56.1%  Recall UP: 45.2%\n",
            "  Grid Search (rbf)... ‚úÖ CV: 51.41%\n",
            "  rbf          Acc: 56.33%  Bal.Acc: 51.90%  F1: 0.6947\n",
            "               Recall DOWN: 15.1%  Recall UP: 88.7%\n",
            "  Grid Search (polynomial)... ‚úÖ CV: 50.30%\n",
            "  polynomial   Acc: 44.94%  Bal.Acc: 50.08%  F1: 0.1300\n",
            "               Recall DOWN: 92.8%  Recall UP: 7.3%\n",
            "\n",
            "--- ANN (1-1-1 + SMOTE) ---\n",
            "  SMOTE uygula... ‚úÖ (1328 samples)\n",
            "  ANN eƒüitimi... ‚úÖ (12 iterations)\n",
            "  ANN          Acc: 56.01%  Bal.Acc: 50.00%  F1: 0.7181\n",
            "               Recall DOWN: 0.0%  Recall UP: 100.0%\n",
            "\n",
            "üèÜ KAR≈ûILA≈ûTIRMA (Balanced Accuracy):\n",
            "   SVM (rbf): 51.90%\n",
            "   ANN (1-1-1):  50.00%\n",
            "   ‚úÖ Winner: SVM\n",
            "\n",
            "================================================================================\n",
            "üìä KSE100\n",
            "================================================================================\n",
            "\n",
            "--- SVM (SMOTE + Class Weight) ---\n",
            "  Grid Search (linear)... ‚úÖ CV: 54.61%\n",
            "  linear       Acc: 56.01%  Bal.Acc: 56.33%  F1: 0.5382\n",
            "               Recall DOWN: 63.6%  Recall UP: 49.1%\n",
            "  Grid Search (rbf)... ‚úÖ CV: 55.01%\n",
            "  rbf          Acc: 53.48%  Bal.Acc: 53.85%  F1: 0.5051\n",
            "               Recall DOWN: 62.3%  Recall UP: 45.5%\n",
            "  Grid Search (polynomial)... ‚úÖ CV: 52.93%\n",
            "  polynomial   Acc: 50.32%  Bal.Acc: 50.26%  F1: 0.5199\n",
            "               Recall DOWN: 49.0%  Recall UP: 51.5%\n",
            "\n",
            "--- ANN (1-1-1 + SMOTE) ---\n",
            "  SMOTE uygula... ‚úÖ (1388 samples)\n",
            "  ANN eƒüitimi... ‚úÖ (12 iterations)\n",
            "  ANN          Acc: 52.22%  Bal.Acc: 50.00%  F1: 0.6861\n",
            "               Recall DOWN: 0.0%  Recall UP: 100.0%\n",
            "\n",
            "üèÜ KAR≈ûILA≈ûTIRMA (Balanced Accuracy):\n",
            "   SVM (linear): 56.33%\n",
            "   ANN (1-1-1):  50.00%\n",
            "   ‚úÖ Winner: SVM\n",
            "\n",
            "================================================================================\n",
            "üìä Nikkei225\n",
            "================================================================================\n",
            "\n",
            "--- SVM (SMOTE + Class Weight) ---\n",
            "  Grid Search (linear)... ‚úÖ CV: 50.95%\n",
            "  linear       Acc: 52.69%  Bal.Acc: 52.09%  F1: 0.5995\n",
            "               Recall DOWN: 35.9%  Recall UP: 68.3%\n",
            "  Grid Search (rbf)... ‚úÖ CV: 53.09%\n",
            "  rbf          Acc: 54.39%  Bal.Acc: 54.07%  F1: 0.5882\n",
            "               Recall DOWN: 45.3%  Recall UP: 62.8%\n",
            "  Grid Search (polynomial)... ‚úÖ CV: 53.66%\n",
            "  polynomial   Acc: 54.39%  Bal.Acc: 54.28%  F1: 0.5660\n",
            "               Recall DOWN: 51.2%  Recall UP: 57.4%\n",
            "\n",
            "--- ANN (1-1-1 + SMOTE) ---\n",
            "  SMOTE uygula... ‚úÖ (1512 samples)\n",
            "  ANN eƒüitimi... ‚úÖ (12 iterations)\n",
            "  ANN          Acc: 51.84%  Bal.Acc: 50.00%  F1: 0.6828\n",
            "               Recall DOWN: 0.0%  Recall UP: 100.0%\n",
            "\n",
            "üèÜ KAR≈ûILA≈ûTIRMA (Balanced Accuracy):\n",
            "   SVM (polynomial): 54.28%\n",
            "   ANN (1-1-1):  50.00%\n",
            "   ‚úÖ Winner: SVM\n",
            "\n",
            "================================================================================\n",
            "üìä SZSE\n",
            "================================================================================\n",
            "\n",
            "--- SVM (SMOTE + Class Weight) ---\n",
            "  Grid Search (linear)... "
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3641341863.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msonuclar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m \u001b[0msonuclar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mana_program\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[0;31m# ============================================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3641341863.py\u001b[0m in \u001b[0;36mana_program\u001b[0;34m()\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkernel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkernel_tipleri\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m                 \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVM_grid_search_with_smote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m                 \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3641341863.py\u001b[0m in \u001b[0;36mSVM_grid_search_with_smote\u001b[0;34m(X_train, y_train, kernel_tipi)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"  Grid Search ({kernel_tipi})...\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m     \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"‚úÖ CV: {grid.best_score_*100:.2f}%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1022\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1569\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1570\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1571\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    968\u001b[0m                     )\n\u001b[1;32m    969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    971\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    972\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         )\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2070\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2072\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2074\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1681\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1682\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1798\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTASK_PENDING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1799\u001b[0m                 ):\n\u001b[0;32m-> 1800\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1801\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hpbnzqn7v87v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}